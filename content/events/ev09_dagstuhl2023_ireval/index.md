---
title: "Dagstuhl Seminar 23031: Frontiers of Information Access Experimentation for Research and Education"
cms_exclude: true
type: talks

draft: false
reading_time: false  # Show estimated reading time?
share: true  # Show social sharing links?
profile: false  # Show author profile?
commentable: false  # Allow visitors to comment? Supported by the Page, Post, and Docs content types.
editable: false  # Allow visitors to edit the page? Supported by the Page, Post, and Docs content types.

event: "Dagstuhl Seminar 23031: Frontiers of Information Access Experimentation for Research and Education"
event_url: "https://www.dagstuhl.de/23031"

location: Schloss Dagstuhl
address:
  street: Oktavie-Allee
  city: Wadern
#  region: CA
  postcode: '66687'
  country: Germany

summary: "Dagstuhl Seminar 23031: Frontiers of Information Access Experimentation for Research and Education"
abstract: |-
  Information access – which includes Information Retrieval (IR), Recommender Systems (RS), and Natural Language Processing (NLP) – has a long tradition of relying heavily on experimental evaluation, dating back to the mid-1950s, a tradition that has driven the research and evolution of the field. However, nowadays, research and development of information access systems are confronted with new challenges: information access systems are called to support a much wider set of user tasks (informational, educational, and entertainment, just to name a few) which are increasingly challenging, and as a result, research settings and available opportunities have evolved substantially (e.g., better platforms, richer data, but also developments within the scientific culture) and shape the way in which we do research and experimentation. Consequently, it is critical that the next generation of scientists is equipped with a portfolio of evaluation methods that reflect the field’s challenges and opportunities, and help ensure internal validity (e.g., measures, statistical analyses, effect sizes, etc., to support establishing a trustworthy cause-effect relationship between treatments and outcomes), construct validity (e.g., measuring the right thing rather than a partial proxy), and external validity (e.g., critically assessing to which extent findings hold in other situations, domains, and user groups). A robust portfolio of such methods will contribute to developing more responsible experimental practices.

  Therefore, we face two problems: Can we re-innovate how we do research and experimentation in the field by addressing emerging challenges in experimental processes to develop the next generation of information access systems? How can a new paradigm of experimentation be leveraged to improve education to give an adequate basis to the new generation of researchers and developers?

  This Dagstuhl Seminar brought together experts from various sub-fields of information access, namely IR, RS, NLP, information science, and human-computer interaction to create a joint understanding of the problems and challenges presented above, to discuss existing solutions and impediments, and to propose next steps to be pursued in the area.

  To stimulate thinking around these themes, prior to the seminar, we challenged participants with the following questions:
  - Which experimentation methodologies are most promising to further develop and create a culture around?
  - In which ways can we consider the concerns related to Fairness, Accountability, and Transparency (FAccT) in the experimentation practices? How can we establish FaccT-E, i.e. FaccT in Experimentation?
  - How can industry and academia better work together on experimentation?
  - How can critical experimentation methods and skills be taught and developed in academic teaching?
  - How can we foster collaboration and run shared infrastructures enabling collaborative and joint experimentation? How to organize shared evaluation activities taking advantage of new hybrid forms of participation?
  
  We started the seminar week with a series of long and short talks delivered by participants, also in response to the above questions. This helped in setting a common ground and understanding and in letting emerge the topics and themes that participants wished to explore as the main output of the seminar.

  This led to the definition of five groups which explored challenges, opportunities, and next steps in the following areas

  - **Reality check**: The working group identified the main challenges in doing real-world studies in RS and IR research – and points to best practices and remaining challenges in both how to do domain-specific or longitudinal studies, how to recruit the right participants, using existing or creating new infrastructure including appropriate data representation, as well as how, why and what to measure.
  - **Human-machine-collaborative relevance judgment frameworks**: The working group studied the motivation for using Large Language Models (LLMs) to automatically generate relevance assessments in information retrieval evaluation, and raises research questions about how LLMs can help human assessors with the assessment task, whether machines can replace humans in assessing and annotating, and what are the conditions under which human assessors cannot be replaced by machines.
  - **Overcoming methodological challenges in IR and RS through awareness and education**: Given the potential limitations of today’s predominant experimentation practices, we find that we need to better equip the various actors in the scientific ecosystem in terms of scientific methods, and we identify a corresponding set of helpful resources and initiatives, which will allow them to adopt a more holistic perspective when evaluating such systems.
  - **Results-blind reviewing**: The current review processes lead to undue emphasis on performance, rejecting papers focusing on insights in case they show no performance improvements. We propose to introduce a results-blind reviewing process forcing reviewers to put more emphasis on the theoretical background, the hypotheses, the methodological plan and the analysis plan of an experiment, thus improving the overall quality of the papers being accepted.
  - **Guidance for authors**: The Information Retrieval community has over time developed expectations regarding papers, but these expectations are largely implicit. In contrast to adjacent disciplines, efforts in the ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR) community have been rather sparse and are mostly due to individuals expressing their own views. Drawing on materials from other disciplines, we have built a draft set of guidelines with the aim of them being understandable, broad, and highly concise. We believe that our proposal is general and uncontroversial, can be used by the main venues, and can be maintained with an open and continuous effort driven by, and for, the community.

# Talk start and end times.
#   End time can optionally be hidden by prefixing the line with `#`.
date: "2023-01-15"
date_end: "2023-01-20"
all_day: true

# Schedule page publish date (NOT talk date).
publishDate: "2023-01-01T00:00:00Z"

authors:
  - Christine Bauer
  - Ben Carterette
  - Nicola Ferro
  - Norbert Fuhr
tags: [Dagstuhl, evaluation, information access, information retrieval, recommender systems, NLP]
categories:
  - event

# Is this a featured talk? (true/false)
featured: false

image:
  caption: 'Dagstuhl Seminar 23031: Frontiers of Information Access Experimentation for Research and Education<br>
  (Jan 15 – Jan 20, 2023)'
  focal_point: "Smart"
  preview_only: false
  placement: 1


links:
#url_code: ""
#url_pdf: ""
#url_slides: ""
#url_video: ""
#url_proceedings: ''
doi: 10.4230/DagRep.13.1.68


projects: [multimethod]
---


{{< cite page="bauer-2023-dagstuhl" view="4" >}}
{{< cite page="bauer-2023-sigir-dagstuhl" view="4" >}}

